{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este problema consiste en implementar una red neuronal que permita clasificar\\\n",
    "la revisiones realizadas en IMDB como positivas o negativas. Para ello vamos a trabajar con\\\n",
    "los datos que provee la librer√≠a keras (datasets.imbd.load_data(num_words=10000)).\\\n",
    "Los datos se encuentran codificados seg√∫n el diccionario imdb.get_word_index(), donde\\\n",
    "cada palabra esta codificada con un n√∫mero. Antes de poder trabajar con los datos es nece-\\\n",
    "sario preprocesar los mismos de forma similar a c√≥mo se hizo con la BD mnist. Analizar el\\\n",
    "rendimiento de la red propuesta, y en caso de overfitting estudie el impacto que tienen las\\\n",
    "distintas variantes de regularizaci√≥n vistas en clase para mejorar la generalizaci√≥n de la red\\\n",
    "(ùêø2, BN y Drop out)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/home/lautaro/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/home/lautaro/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=10000)\n",
    "\n",
    "word_index = keras.datasets.imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['it', 'is', 'in', 'of', 'a', 'br', 'the', 'and', 'to']\n"
     ]
    }
   ],
   "source": [
    "top_values = [i for i in word_index if word_index[i]<10]\n",
    "print(top_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the as on there plot she's iii film that for find that saw better just is along wrong silly awesome or play this you doing was one in own that successful are make and old plot gets unfortunately of on was although except value omar that with her do they gets for that with timing really way that is played character i i what poor set but is along 100 studio on film is missing br received fact to is mercifully br fabulous and them powers is tapes br enjoys indicate good women show to one good played i i was plain film because avoid for of totally it time do period it couple in college in viewers get br of my to of material it yet br out more\n"
     ]
    }
   ],
   "source": [
    "def get_word(word_index, idx):\n",
    "    l = [word for word in word_index if word_index[word] == idx]\n",
    "    return l[0]\n",
    "\n",
    "#Como las reviews ya vienen ordenadas por index, no puedo imprimir el texto,\n",
    "#Solo una secuenca de palabras ordenadas por frecuencia de aparicion\n",
    "def print_review(review, word_index):\n",
    "    streview = []\n",
    "    for idx in review:\n",
    "        streview.append(get_word(word_index, idx))\n",
    "    print(' '.join(streview))\n",
    "    return None\n",
    "\n",
    "print_review(x_train[9], word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 4., 0., 1., 1., 1., 1., 0., 0., 2.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [1, 3, 4, 1, 1, 1, 5, 6, 9, 9]\n",
    "d = {x:X.count(x) for x in X}\n",
    "data = np.zeros((1, 10))\n",
    "data[0, list(d.keys())]+=list(d.values())\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(X, num_words=10000):\n",
    "    m = len(X)\n",
    "    \n",
    "    data = np.zeros((m, num_words), dtype=float)\n",
    "\n",
    "    for i, review in enumerate(X):\n",
    "        d = {idx:review.count(idx) for idx in review}\n",
    "        data[i, list(d.keys())] += list(d.values())\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 10000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain = preprocess(x_train)\n",
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 10000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest = preprocess(x_test)\n",
    "Xtest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez preprocesados los datos, vamos a implementar una red neuronal de 2 capas ocultas de 30 neuronas cada una"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 10000)]           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                100010    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 25)                275       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 26        \n",
      "=================================================================\n",
      "Total params: 100,311\n",
      "Trainable params: 100,311\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=.0001)\n",
    "\n",
    "input = keras.layers.Input(shape=(10000,))\n",
    "l1 = keras.layers.Dense(10, activation='relu', use_bias=True, kernel_regularizer=keras.regularizers.L2(0))(input)\n",
    "l2 = keras.layers.Dense(25, activation='relu', use_bias=True, kernel_regularizer=keras.regularizers.L2(0))(l1)\n",
    "output = keras.layers.Dense(1, activation='linear', use_bias=True)(l2)\n",
    "\n",
    "model = keras.Model(inputs=input, outputs=output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "The Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=opt, loss=keras.losses.BinaryCrossentropy(from_logits=True), \n",
    "              metrics=[keras.metrics.BinaryAccuracy(threshold=.8)])\n",
    "hist3 = model.fit(Xtrain, y_train, validation_data=(Xtest, y_test), epochs=2, \n",
    "                  batch_size=50, verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3159170d9fcce935f4a2f5b40d38978387b4f643b035d22b78e982df0db07ec7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
