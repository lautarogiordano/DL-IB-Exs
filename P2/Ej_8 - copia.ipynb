{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from my_keras import *\n",
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: X=(50000, 32, 32, 3), y=(50000, 1)\n",
      "Test: X=(10000, 32, 32, 3), y=(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "names_dict = {0: 'airplane', 1: 'automobile', 2: 'bird', \n",
    "              3: 'cat', 4: 'deer', 5: 'dog', \n",
    "              6: 'frog', 7: 'horse', 8: 'ship', \n",
    "              9: 'truck'}\n",
    "              \n",
    "(Xtrain, ytrain), (Xtest, ytest) = cifar10.load_data()\n",
    "\n",
    "\n",
    "# summarize loaded dataset\n",
    "print('Train: X=%s, y=%s' % (Xtrain.shape, ytrain.shape))\n",
    "print('Test: X=%s, y=%s' % (Xtest.shape, ytest.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(X):\n",
    "    X_norm = X.reshape(len(X), X[0].size).astype(float)\n",
    "    X_norm -= np.mean(X)\n",
    "    X_norm /= np.std(X).astype(float)\n",
    "    #X_norm = np.hstack((np.ones((X_norm.shape[0], 1)), X_norm)).astype(float)\n",
    "    return X_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3072) (50000, 1)\n"
     ]
    }
   ],
   "source": [
    "Xtrain_n = process(Xtrain)\n",
    "Xtest_n = process(Xtest)\n",
    "\n",
    "testdata = [Xtest_n, ytest]\n",
    "\n",
    "print(Xtrain_n.shape, ytrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0: <class 'my_keras.layers2.Input'>, neurons: 3072\n",
      "Layer 1: <class 'my_keras.layers2.Dense'>, neurons: 100\n",
      "Layer 2: <class 'my_keras.layers2.Dense'>, neurons: 10\n"
     ]
    }
   ],
   "source": [
    "reg1 = regularizers.L2(lambda_=0.01)\n",
    "reg2 = regularizers.L2(lambda_=0.01)\n",
    "reg3 = regularizers.L2(lambda_=0.01)\n",
    "\n",
    "model = models2.Network()\n",
    "\n",
    "model.add(layers2.Input(Xtrain_n.shape[1]))\n",
    "model.add(layers2.Dense(3072, 100, activation=activations.sigmoid(), reg=reg1), scale=.01)\n",
    "model.add(layers2.Dense(100, 10, activation=activations.sigmoid(),reg=reg2), scale=.01)\n",
    "model.printLayers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.64987621, 0.47478916, 0.61493125, 0.39012236, 0.5576118 ,\n",
       "        0.42205731, 0.50304076, 0.56011769, 0.57361812, 0.45519566,\n",
       "        0.55956313, 0.43928686, 0.41630772, 0.62243779, 0.58616471,\n",
       "        0.47459918, 0.499515  , 0.49574157, 0.51297235, 0.53967868,\n",
       "        0.52132281, 0.40069219, 0.44199204, 0.57388915, 0.3611546 ,\n",
       "        0.60365868, 0.47378353, 0.41799474, 0.4742932 , 0.53320877,\n",
       "        0.58151368, 0.3925632 , 0.54663473, 0.45268344, 0.45723761,\n",
       "        0.50306899, 0.52240709, 0.40614584, 0.53659118, 0.45947162,\n",
       "        0.52874326, 0.34307435, 0.48382366, 0.57802371, 0.51397838,\n",
       "        0.52487788, 0.50273016, 0.48376878, 0.48022611, 0.52819496,\n",
       "        0.4705915 , 0.47679101, 0.56692369, 0.52189343, 0.58334909,\n",
       "        0.56096107, 0.52621434, 0.46939463, 0.465032  , 0.50108631,\n",
       "        0.57905794, 0.49006969, 0.68229301, 0.54931473, 0.54471447,\n",
       "        0.51425807, 0.41431838, 0.56456357, 0.56214548, 0.46036865,\n",
       "        0.52232929, 0.4619264 , 0.60109674, 0.49586906, 0.36696121,\n",
       "        0.62382371, 0.41599483, 0.55055564, 0.50044707, 0.48582152,\n",
       "        0.32585726, 0.49809955, 0.54420684, 0.4644509 , 0.53753634,\n",
       "        0.49586486, 0.41731579, 0.44162525, 0.56878424, 0.49310951,\n",
       "        0.43542304, 0.51148785, 0.51649958, 0.5875257 , 0.4999579 ,\n",
       "        0.46319507, 0.49525845, 0.44094687, 0.49737279, 0.55424407],\n",
       "       [0.44034583, 0.45355429, 0.48599265, 0.53195813, 0.49967543,\n",
       "        0.51317507, 0.49127072, 0.4265161 , 0.46923907, 0.50951449,\n",
       "        0.47002799, 0.50071824, 0.62791266, 0.47304466, 0.52636397,\n",
       "        0.49715875, 0.57911306, 0.65567562, 0.51009378, 0.38826759,\n",
       "        0.46959372, 0.54850246, 0.54304337, 0.44731084, 0.49001331,\n",
       "        0.54096581, 0.38530051, 0.43862604, 0.50869963, 0.52435273,\n",
       "        0.46703091, 0.54865501, 0.5901028 , 0.3912676 , 0.68288018,\n",
       "        0.45742772, 0.49863132, 0.45102054, 0.50917882, 0.42832014,\n",
       "        0.48957312, 0.57570051, 0.4577376 , 0.70416655, 0.50415392,\n",
       "        0.38590203, 0.42934766, 0.47504548, 0.58025495, 0.55552602,\n",
       "        0.40898148, 0.62099296, 0.40769967, 0.48454373, 0.44902096,\n",
       "        0.45307845, 0.55081651, 0.62611105, 0.54778334, 0.39895996,\n",
       "        0.45640846, 0.51269671, 0.49918923, 0.48674775, 0.50298547,\n",
       "        0.44007626, 0.43077692, 0.38551172, 0.52655227, 0.33983829,\n",
       "        0.57685768, 0.4369908 , 0.61019407, 0.46778545, 0.47882928,\n",
       "        0.60875992, 0.48417005, 0.65125011, 0.26884745, 0.50000318,\n",
       "        0.40843207, 0.5509632 , 0.62523317, 0.6194692 , 0.43878446,\n",
       "        0.53347621, 0.56287862, 0.56542924, 0.49233997, 0.59719251,\n",
       "        0.43096956, 0.55623585, 0.33646971, 0.54514174, 0.3858693 ,\n",
       "        0.56915433, 0.50428728, 0.46941814, 0.53553153, 0.51428905],\n",
       "       [0.48158199, 0.47672683, 0.35991449, 0.47859935, 0.62939929,\n",
       "        0.51271144, 0.44425024, 0.4731972 , 0.44995719, 0.44500944,\n",
       "        0.23253404, 0.53335702, 0.69383474, 0.38907017, 0.43484451,\n",
       "        0.60322293, 0.57462869, 0.57455513, 0.55395738, 0.4784323 ,\n",
       "        0.53382384, 0.66402444, 0.45969006, 0.34911952, 0.47149488,\n",
       "        0.30828391, 0.48875343, 0.37904474, 0.37139615, 0.57705001,\n",
       "        0.51225068, 0.57752684, 0.44105728, 0.5142714 , 0.61660367,\n",
       "        0.42347121, 0.5188246 , 0.3360043 , 0.57701412, 0.47073929,\n",
       "        0.55694194, 0.58138695, 0.49609833, 0.35365888, 0.57246052,\n",
       "        0.4887971 , 0.52103709, 0.51558351, 0.66239471, 0.50773295,\n",
       "        0.49264725, 0.51904918, 0.30821595, 0.39559345, 0.67606673,\n",
       "        0.39129532, 0.46875522, 0.37290282, 0.40983617, 0.50377645,\n",
       "        0.50501808, 0.37790417, 0.55193281, 0.50537141, 0.66389135,\n",
       "        0.50817666, 0.63216304, 0.37539711, 0.50751051, 0.61316854,\n",
       "        0.4983429 , 0.57053938, 0.32244687, 0.35201266, 0.53539481,\n",
       "        0.58477607, 0.55885614, 0.4774742 , 0.48263109, 0.71560527,\n",
       "        0.6594212 , 0.40298314, 0.53629746, 0.50933252, 0.57384852,\n",
       "        0.49751271, 0.69817716, 0.3805009 , 0.54090936, 0.50590179,\n",
       "        0.75946002, 0.67313529, 0.65874828, 0.37682517, 0.51350702,\n",
       "        0.49794977, 0.47683432, 0.41883004, 0.48443981, 0.46371575],\n",
       "       [0.5630496 , 0.54595058, 0.52066921, 0.34805179, 0.48169264,\n",
       "        0.5516655 , 0.54409109, 0.58957241, 0.60536582, 0.45516067,\n",
       "        0.47667365, 0.41070838, 0.49772384, 0.62184704, 0.54279605,\n",
       "        0.50892802, 0.52135665, 0.44378491, 0.52360854, 0.58571389,\n",
       "        0.4959137 , 0.4703703 , 0.47250291, 0.57571196, 0.4074359 ,\n",
       "        0.69558337, 0.37221942, 0.47691209, 0.50189033, 0.56857883,\n",
       "        0.41461333, 0.40661918, 0.51051859, 0.48982137, 0.48610886,\n",
       "        0.42251984, 0.57579267, 0.47197419, 0.48750071, 0.44473227,\n",
       "        0.50142008, 0.45626573, 0.55897112, 0.43862941, 0.52836229,\n",
       "        0.6186462 , 0.49979383, 0.45545469, 0.46199365, 0.61333545,\n",
       "        0.40619524, 0.43891294, 0.57075553, 0.53136145, 0.50313039,\n",
       "        0.56177669, 0.49646039, 0.45955846, 0.60934826, 0.47424952,\n",
       "        0.63613204, 0.55804763, 0.54420437, 0.62672411, 0.50337566,\n",
       "        0.46399961, 0.44456849, 0.57413924, 0.4799373 , 0.4188532 ,\n",
       "        0.47066005, 0.37705387, 0.6086072 , 0.52470426, 0.3899449 ,\n",
       "        0.58097891, 0.37404292, 0.51171794, 0.57385239, 0.46851876,\n",
       "        0.4035085 , 0.47286957, 0.40781397, 0.55512831, 0.54852393,\n",
       "        0.44163812, 0.38800258, 0.5245254 , 0.52637554, 0.51932412,\n",
       "        0.4158284 , 0.51027843, 0.55722291, 0.51819193, 0.54474504,\n",
       "        0.50428906, 0.5128677 , 0.48055847, 0.4344896 , 0.57431741],\n",
       "       [0.36285001, 0.49284337, 0.46568402, 0.5647218 , 0.34733035,\n",
       "        0.62608633, 0.46254415, 0.47527311, 0.4958079 , 0.49955608,\n",
       "        0.42127679, 0.57801587, 0.5862522 , 0.42638466, 0.48415442,\n",
       "        0.4868872 , 0.48620468, 0.48477608, 0.59418048, 0.37728706,\n",
       "        0.47108161, 0.67640751, 0.4965935 , 0.52034682, 0.40799311,\n",
       "        0.49673296, 0.41038982, 0.46217741, 0.44247096, 0.62926666,\n",
       "        0.3457164 , 0.47990964, 0.39531239, 0.46167449, 0.54473661,\n",
       "        0.37006973, 0.53905586, 0.50423705, 0.49170276, 0.48827268,\n",
       "        0.46099019, 0.6522521 , 0.66494238, 0.44393357, 0.42641104,\n",
       "        0.54679881, 0.60464005, 0.52625453, 0.43761224, 0.51868812,\n",
       "        0.36450234, 0.45294785, 0.37607292, 0.40413274, 0.55658592,\n",
       "        0.45524639, 0.44616152, 0.41000964, 0.62009246, 0.50416128,\n",
       "        0.58505472, 0.3779442 , 0.60865445, 0.4840871 , 0.46471083,\n",
       "        0.50191809, 0.53164658, 0.46790684, 0.42528189, 0.51653371,\n",
       "        0.45730601, 0.39617948, 0.62507336, 0.44001406, 0.45419957,\n",
       "        0.47008419, 0.38837972, 0.56637377, 0.43726127, 0.53377846,\n",
       "        0.43282514, 0.60007283, 0.55723198, 0.5109694 , 0.46545583,\n",
       "        0.57871591, 0.49163453, 0.54791753, 0.6188551 , 0.38364098,\n",
       "        0.47243005, 0.48362959, 0.516632  , 0.57678894, 0.43610356,\n",
       "        0.5778521 , 0.57728143, 0.44585813, 0.47228169, 0.5684279 ],\n",
       "       [0.58403196, 0.66029   , 0.52648342, 0.49534106, 0.57198874,\n",
       "        0.4816998 , 0.49294298, 0.66958873, 0.46381075, 0.55590272,\n",
       "        0.45986638, 0.55563663, 0.5861283 , 0.62681925, 0.53848092,\n",
       "        0.52943292, 0.44598357, 0.31343338, 0.54169976, 0.59761647,\n",
       "        0.40747878, 0.47636002, 0.41412863, 0.48416964, 0.38914161,\n",
       "        0.56923335, 0.38939738, 0.39529774, 0.43607572, 0.65650889,\n",
       "        0.50085849, 0.59931998, 0.48682289, 0.53727404, 0.40890153,\n",
       "        0.49156113, 0.54572414, 0.31982587, 0.52532108, 0.37481701,\n",
       "        0.44314977, 0.39660037, 0.36100387, 0.42062725, 0.5521195 ,\n",
       "        0.68549809, 0.50260422, 0.32690651, 0.62477359, 0.61366308,\n",
       "        0.5472592 , 0.56056689, 0.5591021 , 0.52916892, 0.7488649 ,\n",
       "        0.54465796, 0.61747054, 0.38255014, 0.55999363, 0.56719648,\n",
       "        0.530152  , 0.51844012, 0.70075536, 0.58544575, 0.69466201,\n",
       "        0.57403231, 0.4359603 , 0.56222889, 0.60953857, 0.517963  ,\n",
       "        0.49794545, 0.41144065, 0.614187  , 0.44735194, 0.46031846,\n",
       "        0.63421805, 0.38622868, 0.49730842, 0.55736948, 0.51421817,\n",
       "        0.40956808, 0.48793251, 0.5326185 , 0.57822727, 0.54134398,\n",
       "        0.46435107, 0.40654736, 0.40835286, 0.70353846, 0.54290338,\n",
       "        0.44957277, 0.56682015, 0.50898189, 0.47876829, 0.51021744,\n",
       "        0.513399  , 0.51870575, 0.39303583, 0.48847611, 0.45996672],\n",
       "       [0.56790304, 0.50364106, 0.56826244, 0.39695231, 0.51319551,\n",
       "        0.45308675, 0.57045721, 0.48962182, 0.58360767, 0.41607273,\n",
       "        0.47516182, 0.45963633, 0.57428932, 0.51755627, 0.51469843,\n",
       "        0.41641979, 0.59208461, 0.38887793, 0.64764375, 0.55102908,\n",
       "        0.45537727, 0.47492494, 0.48002154, 0.521501  , 0.43144468,\n",
       "        0.48323338, 0.55967193, 0.50090677, 0.42117937, 0.47995621,\n",
       "        0.52903446, 0.53718141, 0.51539854, 0.38401707, 0.54400406,\n",
       "        0.5739207 , 0.48501398, 0.49565301, 0.48972282, 0.46971515,\n",
       "        0.5461546 , 0.39634958, 0.39732691, 0.59910381, 0.59575982,\n",
       "        0.4766084 , 0.35588669, 0.46079699, 0.57501604, 0.49224783,\n",
       "        0.56582576, 0.44395001, 0.58208393, 0.49812509, 0.57216995,\n",
       "        0.44445756, 0.512117  , 0.49881683, 0.46207237, 0.45505608,\n",
       "        0.59695372, 0.48921231, 0.47337904, 0.44900745, 0.61381903,\n",
       "        0.41004352, 0.4501572 , 0.46973715, 0.49903975, 0.5054849 ,\n",
       "        0.57735673, 0.45955794, 0.556129  , 0.54854518, 0.53751488,\n",
       "        0.46088096, 0.55335561, 0.48297488, 0.54679999, 0.5250306 ,\n",
       "        0.61242003, 0.54253774, 0.52629871, 0.53520784, 0.39816635,\n",
       "        0.51904236, 0.52881813, 0.46377262, 0.63068121, 0.54941871,\n",
       "        0.45725127, 0.51900705, 0.51048485, 0.54887189, 0.41997794,\n",
       "        0.5238433 , 0.46361977, 0.50395011, 0.43076367, 0.57838823],\n",
       "       [0.61288312, 0.48094867, 0.42090328, 0.56283745, 0.50368148,\n",
       "        0.44575356, 0.46299453, 0.40344518, 0.51168824, 0.61835618,\n",
       "        0.58695066, 0.48404162, 0.49799027, 0.50986872, 0.62242489,\n",
       "        0.46777917, 0.441182  , 0.36801405, 0.46924163, 0.4925162 ,\n",
       "        0.40137742, 0.47949287, 0.4958145 , 0.54729933, 0.52817898,\n",
       "        0.58609327, 0.6427644 , 0.41096343, 0.61932549, 0.53206699,\n",
       "        0.44749482, 0.55616293, 0.48490006, 0.49103695, 0.53586394,\n",
       "        0.54429751, 0.46744754, 0.35805714, 0.46621101, 0.45921964,\n",
       "        0.55238284, 0.42104602, 0.3581663 , 0.49475142, 0.4316994 ,\n",
       "        0.61350749, 0.4201483 , 0.40006983, 0.50538962, 0.46319894,\n",
       "        0.57673319, 0.41065262, 0.60820919, 0.55054365, 0.42633563,\n",
       "        0.60257552, 0.51139338, 0.39453475, 0.53498861, 0.55290975,\n",
       "        0.39684392, 0.54691809, 0.51205497, 0.52749315, 0.52589706,\n",
       "        0.43375957, 0.42994047, 0.45899819, 0.57199607, 0.52805113,\n",
       "        0.45814051, 0.43771978, 0.49920604, 0.51049327, 0.41309522,\n",
       "        0.51081513, 0.42626855, 0.44822745, 0.6695319 , 0.58014588,\n",
       "        0.53629296, 0.61527611, 0.58835047, 0.61054359, 0.43165313,\n",
       "        0.57396654, 0.49040093, 0.48082833, 0.58193888, 0.4484619 ,\n",
       "        0.42653342, 0.45792053, 0.3884369 , 0.48020003, 0.54917767,\n",
       "        0.50558617, 0.47016257, 0.46629165, 0.48410562, 0.50736566],\n",
       "       [0.42162401, 0.38523775, 0.51165839, 0.46105317, 0.50994116,\n",
       "        0.36687132, 0.55579777, 0.44759665, 0.45076445, 0.58130647,\n",
       "        0.39800468, 0.50054964, 0.48953563, 0.55682385, 0.50732977,\n",
       "        0.46336926, 0.54555286, 0.51192057, 0.50240084, 0.50114805,\n",
       "        0.51530107, 0.57525066, 0.58106542, 0.46125745, 0.450672  ,\n",
       "        0.34078751, 0.64526671, 0.50783507, 0.44181527, 0.41654795,\n",
       "        0.69417976, 0.62667572, 0.54052511, 0.45668075, 0.54913551,\n",
       "        0.4248074 , 0.53613446, 0.5600444 , 0.45953424, 0.69318541,\n",
       "        0.55518367, 0.59401491, 0.52165871, 0.50389327, 0.46459179,\n",
       "        0.34049897, 0.53238039, 0.77240032, 0.44299222, 0.42739112,\n",
       "        0.55426332, 0.48592455, 0.38325481, 0.48612947, 0.47747024,\n",
       "        0.34790975, 0.50171435, 0.64191621, 0.30686389, 0.55280502,\n",
       "        0.51195968, 0.34563265, 0.37093591, 0.36593397, 0.40843353,\n",
       "        0.43443067, 0.45644122, 0.4220411 , 0.42993551, 0.49395999,\n",
       "        0.60671308, 0.69250074, 0.45475201, 0.36865503, 0.61795341,\n",
       "        0.28694069, 0.65893036, 0.53001106, 0.52888117, 0.58895408,\n",
       "        0.50226144, 0.54869693, 0.54388949, 0.4990784 , 0.37348156,\n",
       "        0.59371965, 0.65964419, 0.50806089, 0.41214851, 0.4116384 ,\n",
       "        0.5941178 , 0.45974462, 0.46541769, 0.45779091, 0.47996815,\n",
       "        0.58715029, 0.54385535, 0.45545043, 0.44166066, 0.53611388],\n",
       "       [0.47479656, 0.62743713, 0.43902555, 0.50036929, 0.47242866,\n",
       "        0.61884501, 0.43890757, 0.58284317, 0.45665475, 0.55468571,\n",
       "        0.45754573, 0.57311509, 0.58686027, 0.51472159, 0.52603666,\n",
       "        0.38232898, 0.56022604, 0.40153464, 0.52840782, 0.48287788,\n",
       "        0.48979216, 0.56211564, 0.48110191, 0.47945747, 0.27836482,\n",
       "        0.6300726 , 0.31944471, 0.47792248, 0.44493408, 0.76700809,\n",
       "        0.28578321, 0.41412198, 0.44920587, 0.63325986, 0.54825628,\n",
       "        0.44584597, 0.61833679, 0.38721918, 0.51092288, 0.55515631,\n",
       "        0.5706042 , 0.46254692, 0.60539662, 0.37869946, 0.50603502,\n",
       "        0.60659124, 0.55025845, 0.34962571, 0.53397702, 0.56054641,\n",
       "        0.57490933, 0.34442829, 0.47583548, 0.62011498, 0.63340757,\n",
       "        0.58849389, 0.52775801, 0.41481476, 0.67426353, 0.50411758,\n",
       "        0.63065005, 0.45422115, 0.59214846, 0.65921444, 0.57111856,\n",
       "        0.50013874, 0.56336144, 0.45133329, 0.60565322, 0.43830927,\n",
       "        0.43152697, 0.27157468, 0.58616229, 0.51696743, 0.34057952,\n",
       "        0.53227571, 0.36877863, 0.33030646, 0.5979956 , 0.58269755,\n",
       "        0.58532701, 0.5816814 , 0.32436139, 0.52962338, 0.54121774,\n",
       "        0.49600286, 0.5725657 , 0.37710579, 0.60959366, 0.53464696,\n",
       "        0.50346977, 0.57560817, 0.59355287, 0.32492142, 0.53535254,\n",
       "        0.52612605, 0.48347631, 0.48592834, 0.48032432, 0.62685309]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].forward(Xtrain_n[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1170.3779277987928"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(Xtrain_n[0:1])\n",
    "pred = model.layers[2].S[0:1]\n",
    "los = losses.MSE_img()\n",
    "los(pred, ytrain[0:1])\n",
    "#los.gradient(pred, ytrain[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train loss: 0.0846\n",
      " Accuracy test: 10.43\n",
      "Epoch 2, Train loss: 0.0867\n",
      " Accuracy test: 10.37\n",
      "Epoch 4, Train loss: 0.0883\n",
      " Accuracy test: 10.35\n",
      "Epoch 6, Train loss: 0.0895\n",
      " Accuracy test: 10.19\n",
      "Epoch 8, Train loss: 0.0905\n",
      " Accuracy test: 10.10\n",
      "Epoch 10, Train loss: 0.0913\n",
      " Accuracy test: 9.99\n",
      "Epoch 12, Train loss: 0.0929\n",
      " Accuracy test: 10.11\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9d4499e6b5d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m loss_hist = model.fit(Xtrain_n, ytrain, loss=losses.MSE_img(), opt=optimizers.SGD(alpha=.001), \n\u001b[0m\u001b[1;32m      2\u001b[0m                       metric=metrics.acc_img, testdata=testdata, epochs=20, batch_size=100)\n",
      "\u001b[0;32m~/Desktop/Workspace/Deep_Learning/Practicas/DL-IB-Exs/P2/my_keras/models2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, loss, opt, metric, testdata, epochs, batch_size)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mloss_hist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtestdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Workspace/Deep_Learning/Practicas/DL-IB-Exs/P2/my_keras/optimizers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, y, model, loss, batch_size)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0myb_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mloss_epoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Workspace/Deep_Learning/Practicas/DL-IB-Exs/P2/my_keras/models2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, Xb, up_to)\u001b[0m\n\u001b[1;32m     34\u001b[0m                     \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                     \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Workspace/Deep_Learning/Practicas/DL-IB-Exs/P2/my_keras/layers2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, Sprev)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSprev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mSprevio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSprev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSprev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSprevio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_hist = model.fit(Xtrain_n, ytrain, loss=losses.MSE_img(), opt=optimizers.SGD(alpha=.001), \n",
    "                      metric=metrics.acc_img, testdata=testdata, epochs=20, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.63518956e-03,  4.43008610e-04,  2.32399639e-03, ...,\n",
       "         8.85124166e-04,  2.60605594e-03,  5.73648587e-04],\n",
       "       [-1.54371139e-04, -3.94958108e-04,  7.98150223e-04, ...,\n",
       "         2.56055863e-04, -8.48537182e-04,  7.75700747e-05],\n",
       "       [ 9.47214680e-04, -6.42951648e-05, -2.84484968e-04, ...,\n",
       "        -1.17979976e-04,  1.35478683e-03,  9.87858088e-04],\n",
       "       ...,\n",
       "       [ 4.42185719e-04,  7.89967056e-04,  1.26746709e-03, ...,\n",
       "         3.12508249e-04,  6.65931970e-04,  1.04949274e-03],\n",
       "       [ 1.17649214e-03,  7.91376767e-04, -5.24682169e-04, ...,\n",
       "        -1.15297209e-03,  3.20626098e-04, -1.05722395e-03],\n",
       "       [-6.81906537e-04, -4.06267391e-04,  6.89493368e-04, ...,\n",
       "         7.32166339e-05, -1.02744134e-03, -3.00618236e-04]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.712000000000002 10.780000000000001\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_hist)\n",
    "print(100*metrics.acc_img(model.predict(Xtrain_n), ytrain), \n",
    "      100*metrics.acc_img(model.predict(Xtest_n), ytest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3159170d9fcce935f4a2f5b40d38978387b4f643b035d22b78e982df0db07ec7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
