{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import image\n",
    "from PIL import UnidentifiedImageError\n",
    "from skimage.transform import resize\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lautaro\\anaconda3\\lib\\site-packages\\PIL\\TiffImagePlugin.py:822: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    }
   ],
   "source": [
    "path = 'C:\\\\Users\\\\Lautaro\\\\Desktop\\\\Lautaro\\\\asd\\\\2021\\\\Doctorado\\\\Materias\\\\Deep Learning (2020)\\\\Datos\\\\CatsvDogs'\n",
    "\n",
    "cats = os.path.join(path, 'Cat')\n",
    "dogs = os.path.join(path, 'Dog')\n",
    "\n",
    "data = []\n",
    "\n",
    "for cat in os.listdir(cats):\n",
    "    try:\n",
    "        curr_img = image.imread(os.path.join(cats, cat))\n",
    "        res_img = resize(curr_img, (64, 64), anti_aliasing=0)\n",
    "        shape = res_img.shape\n",
    "        if shape == (64,64,3):\n",
    "            data.append(res_img)\n",
    "\n",
    "        #A veces la imagen se lee con un 4to canal lleno de unos, lo saco\n",
    "        elif shape == (64,64,4):\n",
    "            data.append(res_img[...,:3])\n",
    "\n",
    "    except UnidentifiedImageError:\n",
    "        pass\n",
    "\n",
    "n_cats = len(data)\n",
    "y = np.zeros((n_cats))\n",
    "\n",
    "for dog in os.listdir(dogs):\n",
    "    try:\n",
    "        curr_img = image.imread(os.path.join(dogs, dog))\n",
    "        res_img = resize(curr_img, (64, 64), anti_aliasing=0)\n",
    "        shape = res_img.shape\n",
    "        if shape == (64,64,3):\n",
    "            data.append(res_img)\n",
    "        elif shape == (64,64,4):\n",
    "            data.append(res_img[...,:3])\n",
    "          \n",
    "    except UnidentifiedImageError:\n",
    "        pass\n",
    "        \n",
    "\n",
    "n_dogs = len(data) - n_cats\n",
    "y = np.append(y, np.ones((n_dogs)))\n",
    "\n",
    "data = np.stack(data, axis=0)\n",
    "\n",
    "\n",
    "print('n_cats:', n_cats, ' n_dogs:', n_dogs, ' data shape:', data.shape)\n",
    "plt.imshow(data[143])\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all input arrays must have the same shape",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Lautaro\\Desktop\\Lautaro\\asd\\2021\\Doctorado\\Materias\\Deep Learning (2020)\\Practicas\\Mias\\P5\\Ej_1.ipynb Celda 3\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lautaro/Desktop/Lautaro/asd/2021/Doctorado/Materias/Deep%20Learning%20%282020%29/Practicas/Mias/P5/Ej_1.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mstack(data, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Lautaro/Desktop/Lautaro/asd/2021/Doctorado/Materias/Deep%20Learning%20%282020%29/Practicas/Mias/P5/Ej_1.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m df \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mstack((data, y))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lautaro/Desktop/Lautaro/asd/2021/Doctorado/Materias/Deep%20Learning%20%282020%29/Practicas/Mias/P5/Ej_1.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m df\u001b[39m.\u001b[39mshape\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mstack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Lautaro\\anaconda3\\lib\\site-packages\\numpy\\core\\shape_base.py:426\u001b[0m, in \u001b[0;36mstack\u001b[1;34m(arrays, axis, out)\u001b[0m\n\u001b[0;32m    424\u001b[0m shapes \u001b[39m=\u001b[39m {arr\u001b[39m.\u001b[39mshape \u001b[39mfor\u001b[39;00m arr \u001b[39min\u001b[39;00m arrays}\n\u001b[0;32m    425\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(shapes) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 426\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mall input arrays must have the same shape\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    428\u001b[0m result_ndim \u001b[39m=\u001b[39m arrays[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mndim \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    429\u001b[0m axis \u001b[39m=\u001b[39m normalize_axis_index(axis, result_ndim)\n",
      "\u001b[1;31mValueError\u001b[0m: all input arrays must have the same shape"
     ]
    }
   ],
   "source": [
    "data = np.stack(data, axis=0)\n",
    "\n",
    "df = np.stack((data, y))\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aumentacion de datos\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.RandomFlip(\"horizontal\"),\n",
    "        keras.layers.RandomRotation(factor=(-0.2, 0.2)),\n",
    "        keras.layers.RandomTranslation(height_factor=(-0.2, 0.2), \n",
    "                                       width_factor=(-0.2, 0.2)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a tf.data pipeline of augmented images (and their labels)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.batch(256).map(lambda x, y: (data_augmentation(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(hist):\n",
    "    fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(11,4))\n",
    "    ax1.plot(hist.history['loss'], label='CCE')\n",
    "    ax1.plot(hist.history['val_loss'], label='val_CCE')\n",
    "    ax1.set_xlabel('Epocas', fontsize=15)\n",
    "    ax1.set_ylabel('Loss', fontsize=15)\n",
    "    ax1.legend(loc='best')\n",
    "\n",
    "    ax2.plot(hist.history['sparse_categorical_accuracy'], label='acc')\n",
    "    ax2.plot(hist.history['val_sparse_categorical_accuracy'], label='val_acc')\n",
    "    ax2.set_xlabel('Epocas', fontsize=15)\n",
    "    ax2.set_ylabel('Accuracy', fontsize=15)\n",
    "    ax2.legend(loc='best')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "reg = keras.regularizers.L2(l2=1e-3)\n",
    "drop_r = 0.4\n",
    "\n",
    "model = keras.models.Sequential(name='AlexNet')\n",
    "\n",
    "#Capas convolucionales\n",
    "\n",
    "model.add(keras.layers.Input(shape=(32,32,3)))\n",
    "model.add(keras.layers.Rescaling(1.0 / 255))\n",
    "\n",
    "model.add(keras.layers.Conv2D(128, 5, strides=1, activation='relu', padding='same'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=3, strides=1))\n",
    "\n",
    "model.add(keras.layers.Conv2D(128, 3, strides=1, activation='relu', padding='same'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=3, strides=2))\n",
    "\n",
    "model.add(keras.layers.Conv2D(352, 3, strides=2, activation='relu', padding='same'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Conv2D(352, 3, strides=1, activation='relu', padding='same'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Conv2D(256, 3, strides=1, activation='relu', padding='same'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=3, strides=1))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dropout(rate=drop_r))\n",
    "\n",
    "\n",
    "#Capas densas\n",
    "\n",
    "model.add(keras.layers.Dense(2048, activation='relu', kernel_regularizer=reg))\n",
    "model.add(keras.layers.Dropout(rate=drop_r))\n",
    "model.add(keras.layers.Dense(2048, activation='relu', kernel_regularizer=reg))\n",
    "model.add(keras.layers.Dropout(rate=drop_r))\n",
    "model.add(keras.layers.Dense(10, activation='softmax', kernel_regularizer=reg))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClearMemory(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        gc.collect()\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "  if epoch==10 or epoch == 25 or epoch == 50 or epoch == 75:\n",
    "    return lr/3\n",
    "  else:\n",
    "    return lr\n",
    "\n",
    "\n",
    "callbacks_list=[\n",
    "    keras.callbacks.LearningRateScheduler(\n",
    "    scheduler, verbose=0\n",
    "    ),\n",
    "    ClearMemory()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=.0003)\n",
    "\n",
    "\n",
    "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy',\n",
    "              metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "hist = model.fit(train_dataset, validation_data=(x_test, y_test), \n",
    "                 callbacks=callbacks_list, epochs=100, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b045fddb768a69d708aeb44bac4815a8765073d6505277d1278f194b80f63e22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
